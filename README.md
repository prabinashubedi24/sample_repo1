# ğŸ§  Cyber Safety Detection System (Grooming & Bullying)

This project develops an AI-based cyber safety detection system that classifies text messages as **Normal**, **Grooming**, or **Bullying**. It uses a combination of classical machine learning (TF-IDF + Logistic Regression) and a fine-tuned **DistilBERT** transformer model for high-accuracy text classification.

---

## ğŸš€ Features

- Text preprocessing and cleaning  
- Feature engineering (length, punctuation, numerics, uppercase patterns)  
- Exploratory Data Analysis (EDA)  
- Handling class imbalance using SMOTE and Random Under-Sampling  
- Baseline ML model using TF-IDF + Logistic Regression  
- Fine-tuned DistilBERT models for grooming and bullying datasets  
- Unified prediction combining both models  
- **Streamlit web app** for real-time message classification  
- Visualizations: confusion matrices, performance comparison charts  

---

## ğŸ“Š Model Performance

| Task | Model | Accuracy |
|------|--------|----------|
| Grooming Detection | DistilBERT | **98.82%** |
| Bullying Detection | DistilBERT | **82.68%** |

DistilBERT significantly outperforms classical machine learning baselines.

---

## ğŸ“ Project Structure

```
CyberSafety-Detection/
â”‚
â”œâ”€â”€ cyber_final.py
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ grooming_train_sample.csv
â”‚   â”œâ”€â”€ grooming_test_sample.csv
â”‚   â””â”€â”€ bullying_sample.csv
â”‚
â”œâ”€â”€ models/  (optional)
â”‚   â”œâ”€â”€ grooming_model_distilbert/
â”‚   â””â”€â”€ bullying_model_distilbert/
â”‚
â””â”€â”€ outputs/
    â”œâ”€â”€ cm_grooming.png
    â”œâ”€â”€ cm_bullying.png
    â””â”€â”€ metrics_comparison.png
```

---

## â–¶ï¸ How to Run

### **1. Install dependencies**
```
pip install -r requirements.txt
```

### **2. Run the main script**
```
python cyber_final.py
```

### **3. Run the Streamlit app**
```
streamlit run app.py
```

---

## ğŸŒ Streamlit App

The app provides a simple UI where users can input a message and receive a prediction showing whether it contains grooming, bullying, or normal content.

---

## ğŸ™Œ Author

**Prabina Subedi**

---

## ğŸ“Œ Notes

- Only sample datasets are included for privacy reasons.  
- Full models may not be uploaded due to size limits; links can be provided if needed.

---

## ğŸ“œ License

MIT License 
